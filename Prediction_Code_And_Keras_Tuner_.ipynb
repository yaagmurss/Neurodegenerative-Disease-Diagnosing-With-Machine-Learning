{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "A4Wcz2gBk557"
      },
      "source": [
        "#@title Default title text\n",
        "!pip install -U keras-tuner\n",
        "!pip install hyperopt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDgIKaBblGvD",
        "outputId": "1c4a6114-fa1a-4403-a8df-820c5d793475"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eKUKT5Zg32i",
        "outputId": "6fa1fdad-0bed-4bbd-d5c2-0ff05609b9d7"
      },
      "source": [
        "#Prediction Code#\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Activation , Dropout\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "import pickle\n",
        "from keras.utils import np_utils\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch_size = 32\n",
        "img_height = 100\n",
        "img_width = 100\n",
        "\n",
        "train_dir='/content/drive/MyDrive/Colab Notebooks/train-test-80-20-Vol2/train-test-80-20/Train-Test-80-20/Train'\n",
        "test_dir='/content/drive/MyDrive/Colab Notebooks/train-test-80-20-Vol2/train-test-80-20/Train-Test-80-20/Test'\n",
        "validation_dir='/content/drive/MyDrive/Colab Notebooks/train-test-80-20-Vol2/train-test-80-20/Train-Test-80-20/Test'\n",
        "\n",
        "labels = ['Hasta', 'Saglikli']\n",
        "img_size = 100\n",
        "\n",
        "def get_data(data_dir):\n",
        "    data = [] \n",
        "    for label in labels: \n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img))[...,::-1]\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) \n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)\n",
        "\n",
        "\n",
        "train=get_data(train_dir)\n",
        "test=get_data(test_dir)\n",
        "valid=get_data(validation_dir)\n",
        "\n",
        "\n",
        "x_train=[]\n",
        "y_train=[]\n",
        "\n",
        "x_test=[]\n",
        "y_test=[]\n",
        "\n",
        "x_val=[]\n",
        "y_val=[]\n",
        "\n",
        "\n",
        "for feature, label in train:\n",
        "    x_train.append(feature)\n",
        "    y_train.append(label)\n",
        "\n",
        "for feature, label in test:\n",
        "    x_test.append(feature)\n",
        "    y_test.append(label)\n",
        "\n",
        "for feature, label in valid:\n",
        "    x_val.append(feature)\n",
        "    y_val.append(label)\n",
        "\n",
        "\n",
        "x_train = np.array(x_train) /255.0\n",
        "x_train.reshape(-1, img_size, img_size, 1)\n",
        "y_train = np.array(y_train)\n",
        "y_train=np_utils.to_categorical(y_train) \n",
        "\n",
        "x_test = np.array(x_test) /255.0\n",
        "x_test.reshape(-1, img_size, img_size, 1)\n",
        "y_test = np.array(y_test)\n",
        "y_test=np_utils.to_categorical(y_test) \n",
        "\n",
        "x_val = np.array(x_val) /255.0\n",
        "x_val.reshape(-1, img_size, img_size, 1)\n",
        "y_val = np.array(y_val)\n",
        "y_val=np_utils.to_categorical(y_val) \n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "x_train,y_train=shuffle(x_train,y_train)\n",
        "x_test,y_test=shuffle(x_test,y_test)\n",
        "x_val,y_val=shuffle(x_val,y_val)\n",
        "\n",
        "train_datagen=ImageDataGenerator(brightness_range=(0.1,1.0))\n",
        "train_datagen.fit(x_train)\n",
        "\n",
        "model=keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(128,(3,3),input_shape=x_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Activation('tanh'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(filters=64,kernel_size=5))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(filters=16,kernel_size=1))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "                  optimizer=keras.optimizers.Adam(learning_rate=1e-5,beta_1=0.9,\n",
        "                                 beta_2=0.9)\n",
        "                  ,metrics=[\"accuracy\"])\n",
        "    \n",
        "history = model.fit(x_train,y_train,32,200)#,validation_data=(x_test,y_test))\n",
        "    \n",
        "from sklearn.metrics import classification_report\n",
        "y_test=np.argmax(y_test, axis=1)\n",
        "predictions = model.predict_classes(x_test)\n",
        "predictions = predictions.reshape(1,-1)[0]\n",
        "print(classification_report(y_test, predictions, target_names = ['hasta (Class 0)','saglikli (Class 1)']))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.7002 - accuracy: 0.4866\n",
            "Epoch 2/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6772 - accuracy: 0.5736\n",
            "Epoch 3/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6803 - accuracy: 0.5562\n",
            "Epoch 4/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6644 - accuracy: 0.7486\n",
            "Epoch 5/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6435 - accuracy: 0.5674\n",
            "Epoch 6/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6237 - accuracy: 0.6028\n",
            "Epoch 7/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.6074 - accuracy: 0.7033\n",
            "Epoch 8/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.5975 - accuracy: 0.7894\n",
            "Epoch 9/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.5715 - accuracy: 0.7668\n",
            "Epoch 10/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.5601 - accuracy: 0.8275\n",
            "Epoch 11/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.5455 - accuracy: 0.7662\n",
            "Epoch 12/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.5182 - accuracy: 0.8386\n",
            "Epoch 13/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.5195 - accuracy: 0.8186\n",
            "Epoch 14/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.4963 - accuracy: 0.8309\n",
            "Epoch 15/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.4760 - accuracy: 0.8317\n",
            "Epoch 16/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.4485 - accuracy: 0.8292\n",
            "Epoch 17/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.4351 - accuracy: 0.8586\n",
            "Epoch 18/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.4410 - accuracy: 0.8474\n",
            "Epoch 19/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.4168 - accuracy: 0.8171\n",
            "Epoch 20/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3926 - accuracy: 0.8900\n",
            "Epoch 21/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3782 - accuracy: 0.8590\n",
            "Epoch 22/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3548 - accuracy: 0.8924\n",
            "Epoch 23/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3701 - accuracy: 0.9024\n",
            "Epoch 24/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3966 - accuracy: 0.8280\n",
            "Epoch 25/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.4234 - accuracy: 0.7632\n",
            "Epoch 26/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3514 - accuracy: 0.8752\n",
            "Epoch 27/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3480 - accuracy: 0.8642\n",
            "Epoch 28/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3346 - accuracy: 0.8459\n",
            "Epoch 29/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3403 - accuracy: 0.8654\n",
            "Epoch 30/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3549 - accuracy: 0.8500\n",
            "Epoch 31/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3226 - accuracy: 0.8774\n",
            "Epoch 32/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3193 - accuracy: 0.8777\n",
            "Epoch 33/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3123 - accuracy: 0.8632\n",
            "Epoch 34/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3258 - accuracy: 0.8740\n",
            "Epoch 35/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3206 - accuracy: 0.8671\n",
            "Epoch 36/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2965 - accuracy: 0.8812\n",
            "Epoch 37/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2956 - accuracy: 0.8869\n",
            "Epoch 38/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2834 - accuracy: 0.8788\n",
            "Epoch 39/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3124 - accuracy: 0.8589\n",
            "Epoch 40/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2837 - accuracy: 0.8437\n",
            "Epoch 41/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2645 - accuracy: 0.8922\n",
            "Epoch 42/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2869 - accuracy: 0.8710\n",
            "Epoch 43/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2532 - accuracy: 0.9114\n",
            "Epoch 44/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2808 - accuracy: 0.8549\n",
            "Epoch 45/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2842 - accuracy: 0.8843\n",
            "Epoch 46/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.3050 - accuracy: 0.8637\n",
            "Epoch 47/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2838 - accuracy: 0.8693\n",
            "Epoch 48/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2765 - accuracy: 0.8883\n",
            "Epoch 49/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2618 - accuracy: 0.8994\n",
            "Epoch 50/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2387 - accuracy: 0.9034\n",
            "Epoch 51/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2737 - accuracy: 0.8551\n",
            "Epoch 52/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2373 - accuracy: 0.8930\n",
            "Epoch 53/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2265 - accuracy: 0.9165\n",
            "Epoch 54/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2581 - accuracy: 0.8726\n",
            "Epoch 55/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2931 - accuracy: 0.8865\n",
            "Epoch 56/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2870 - accuracy: 0.8531\n",
            "Epoch 57/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2278 - accuracy: 0.9096\n",
            "Epoch 58/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2306 - accuracy: 0.8906\n",
            "Epoch 59/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2305 - accuracy: 0.8962\n",
            "Epoch 60/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2192 - accuracy: 0.9071\n",
            "Epoch 61/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2186 - accuracy: 0.9055\n",
            "Epoch 62/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2494 - accuracy: 0.8927\n",
            "Epoch 63/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2303 - accuracy: 0.9169\n",
            "Epoch 64/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2144 - accuracy: 0.9256\n",
            "Epoch 65/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2098 - accuracy: 0.9063\n",
            "Epoch 66/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2302 - accuracy: 0.9044\n",
            "Epoch 67/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2442 - accuracy: 0.8903\n",
            "Epoch 68/200\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.2404 - accuracy: 0.9084\n",
            "Epoch 69/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2187 - accuracy: 0.9084\n",
            "Epoch 70/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2044 - accuracy: 0.9173\n",
            "Epoch 71/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1945 - accuracy: 0.9361\n",
            "Epoch 72/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2016 - accuracy: 0.9211\n",
            "Epoch 73/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1892 - accuracy: 0.9419\n",
            "Epoch 74/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2276 - accuracy: 0.9184\n",
            "Epoch 75/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2022 - accuracy: 0.9276\n",
            "Epoch 76/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1903 - accuracy: 0.9349\n",
            "Epoch 77/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2068 - accuracy: 0.9467\n",
            "Epoch 78/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1608 - accuracy: 0.9459\n",
            "Epoch 79/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2230 - accuracy: 0.9091\n",
            "Epoch 80/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2076 - accuracy: 0.8939\n",
            "Epoch 81/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1829 - accuracy: 0.9465\n",
            "Epoch 82/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1724 - accuracy: 0.9149\n",
            "Epoch 83/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1826 - accuracy: 0.9408\n",
            "Epoch 84/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.2072 - accuracy: 0.9089\n",
            "Epoch 85/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1742 - accuracy: 0.9290\n",
            "Epoch 86/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1657 - accuracy: 0.9564\n",
            "Epoch 87/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1732 - accuracy: 0.9315\n",
            "Epoch 88/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1716 - accuracy: 0.9478\n",
            "Epoch 89/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1611 - accuracy: 0.9617\n",
            "Epoch 90/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1846 - accuracy: 0.9263\n",
            "Epoch 91/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1661 - accuracy: 0.9503\n",
            "Epoch 92/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1595 - accuracy: 0.9480\n",
            "Epoch 93/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1898 - accuracy: 0.9164\n",
            "Epoch 94/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1564 - accuracy: 0.9567\n",
            "Epoch 95/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1620 - accuracy: 0.9357\n",
            "Epoch 96/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1502 - accuracy: 0.9465\n",
            "Epoch 97/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1885 - accuracy: 0.9420\n",
            "Epoch 98/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1712 - accuracy: 0.9407\n",
            "Epoch 99/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1830 - accuracy: 0.9085\n",
            "Epoch 100/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1739 - accuracy: 0.9485\n",
            "Epoch 101/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1721 - accuracy: 0.9247\n",
            "Epoch 102/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1684 - accuracy: 0.9434\n",
            "Epoch 103/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1744 - accuracy: 0.9207\n",
            "Epoch 104/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1542 - accuracy: 0.9579\n",
            "Epoch 105/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1526 - accuracy: 0.9325\n",
            "Epoch 106/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1680 - accuracy: 0.9312\n",
            "Epoch 107/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1420 - accuracy: 0.9508\n",
            "Epoch 108/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1429 - accuracy: 0.9544\n",
            "Epoch 109/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1549 - accuracy: 0.9574\n",
            "Epoch 110/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1603 - accuracy: 0.9483\n",
            "Epoch 111/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1406 - accuracy: 0.9750\n",
            "Epoch 112/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1399 - accuracy: 0.9628\n",
            "Epoch 113/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1579 - accuracy: 0.9569\n",
            "Epoch 114/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1568 - accuracy: 0.9373\n",
            "Epoch 115/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1603 - accuracy: 0.9308\n",
            "Epoch 116/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1363 - accuracy: 0.9652\n",
            "Epoch 117/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1461 - accuracy: 0.9452\n",
            "Epoch 118/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1541 - accuracy: 0.9478\n",
            "Epoch 119/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1749 - accuracy: 0.9185\n",
            "Epoch 120/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1467 - accuracy: 0.9776\n",
            "Epoch 121/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1245 - accuracy: 0.9615\n",
            "Epoch 122/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1234 - accuracy: 0.9866\n",
            "Epoch 123/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1704 - accuracy: 0.9152\n",
            "Epoch 124/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1744 - accuracy: 0.9232\n",
            "Epoch 125/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1133 - accuracy: 0.9655\n",
            "Epoch 126/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1560 - accuracy: 0.9474\n",
            "Epoch 127/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1404 - accuracy: 0.9650\n",
            "Epoch 128/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1311 - accuracy: 0.9619\n",
            "Epoch 129/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1421 - accuracy: 0.9541\n",
            "Epoch 130/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1288 - accuracy: 0.9607\n",
            "Epoch 131/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1266 - accuracy: 0.9699\n",
            "Epoch 132/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1244 - accuracy: 0.9438\n",
            "Epoch 133/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1634 - accuracy: 0.9374\n",
            "Epoch 134/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1432 - accuracy: 0.9393\n",
            "Epoch 135/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1264 - accuracy: 0.9760\n",
            "Epoch 136/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1323 - accuracy: 0.9720\n",
            "Epoch 137/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1121 - accuracy: 0.9632\n",
            "Epoch 138/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1185 - accuracy: 0.9813\n",
            "Epoch 139/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1220 - accuracy: 0.9617\n",
            "Epoch 140/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1256 - accuracy: 0.9624\n",
            "Epoch 141/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1164 - accuracy: 0.9731\n",
            "Epoch 142/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1087 - accuracy: 0.9791\n",
            "Epoch 143/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1308 - accuracy: 0.9619\n",
            "Epoch 144/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1381 - accuracy: 0.9354\n",
            "Epoch 145/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1174 - accuracy: 0.9651\n",
            "Epoch 146/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1222 - accuracy: 0.9834\n",
            "Epoch 147/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1215 - accuracy: 0.9491\n",
            "Epoch 148/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1443 - accuracy: 0.9556\n",
            "Epoch 149/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1067 - accuracy: 0.9731\n",
            "Epoch 150/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1106 - accuracy: 0.9677\n",
            "Epoch 151/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1351 - accuracy: 0.9658\n",
            "Epoch 152/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1098 - accuracy: 0.9766\n",
            "Epoch 153/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1057 - accuracy: 0.9801\n",
            "Epoch 154/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1434 - accuracy: 0.9338\n",
            "Epoch 155/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1066 - accuracy: 0.9771\n",
            "Epoch 156/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1067 - accuracy: 0.9834\n",
            "Epoch 157/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0946 - accuracy: 0.9882\n",
            "Epoch 158/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0979 - accuracy: 0.9684\n",
            "Epoch 159/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1325 - accuracy: 0.9543\n",
            "Epoch 160/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1012 - accuracy: 0.9647\n",
            "Epoch 161/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1159 - accuracy: 0.9633\n",
            "Epoch 162/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0886 - accuracy: 0.9939\n",
            "Epoch 163/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0924 - accuracy: 0.9797\n",
            "Epoch 164/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0836 - accuracy: 0.9955\n",
            "Epoch 165/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1067 - accuracy: 0.9671\n",
            "Epoch 166/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0980 - accuracy: 0.9907\n",
            "Epoch 167/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1077 - accuracy: 0.9781\n",
            "Epoch 168/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1007 - accuracy: 0.9769\n",
            "Epoch 169/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1014 - accuracy: 0.9784\n",
            "Epoch 170/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1043 - accuracy: 0.9751\n",
            "Epoch 171/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.1316 - accuracy: 0.9455\n",
            "Epoch 172/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0768 - accuracy: 0.9909\n",
            "Epoch 173/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0944 - accuracy: 0.9759\n",
            "Epoch 174/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0853 - accuracy: 0.9974\n",
            "Epoch 175/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0877 - accuracy: 0.9856\n",
            "Epoch 176/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0907 - accuracy: 0.9929\n",
            "Epoch 177/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0912 - accuracy: 0.9773\n",
            "Epoch 178/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0953 - accuracy: 0.9739\n",
            "Epoch 179/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0737 - accuracy: 0.9928\n",
            "Epoch 180/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0974 - accuracy: 0.9774\n",
            "Epoch 181/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0764 - accuracy: 0.9846\n",
            "Epoch 182/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0869 - accuracy: 0.9856\n",
            "Epoch 183/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0947 - accuracy: 0.9758\n",
            "Epoch 184/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0903 - accuracy: 0.9892\n",
            "Epoch 185/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0688 - accuracy: 0.9931\n",
            "Epoch 186/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0971 - accuracy: 0.9943\n",
            "Epoch 187/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0742 - accuracy: 0.9874\n",
            "Epoch 188/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0709 - accuracy: 0.9896\n",
            "Epoch 189/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0718 - accuracy: 0.9974\n",
            "Epoch 190/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0876 - accuracy: 0.9843\n",
            "Epoch 191/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0739 - accuracy: 0.9900\n",
            "Epoch 192/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0764 - accuracy: 0.9988\n",
            "Epoch 193/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0751 - accuracy: 0.9886\n",
            "Epoch 194/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0767 - accuracy: 0.9951\n",
            "Epoch 195/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0684 - accuracy: 0.9880\n",
            "Epoch 196/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0711 - accuracy: 0.9882\n",
            "Epoch 197/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0663 - accuracy: 0.9938\n",
            "Epoch 198/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0807 - accuracy: 0.9824\n",
            "Epoch 199/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0738 - accuracy: 0.9807\n",
            "Epoch 200/200\n",
            "7/7 [==============================] - 7s 1s/step - loss: 0.0758 - accuracy: 0.9947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                    precision    recall  f1-score   support\n",
            "\n",
            "   hasta (Class 0)       0.90      0.96      0.93        28\n",
            "saglikli (Class 1)       0.96      0.89      0.93        28\n",
            "\n",
            "          accuracy                           0.93        56\n",
            "         macro avg       0.93      0.93      0.93        56\n",
            "      weighted avg       0.93      0.93      0.93        56\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDwNGthobVim"
      },
      "source": [
        "#####MAIN SEARCH BAYESIAN##############\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Activation , Dropout\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner import tuners\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "import time\n",
        "import pickle\n",
        "from keras.utils import np_utils\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import kerastuner \n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "LOG_DIR = f\"{int(time.time())}\"\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=LOG_DIR)\n",
        "\n",
        "batch_size = 32\n",
        "img_height = 150\n",
        "img_width = 150\n",
        "\n",
        "train_dir='/content/drive/MyDrive/Colab Notebooks/train-test-60-15-25/train-test-80-20/Train-Test-80-20/Train'\n",
        "test_dir='/content/drive/MyDrive/Colab Notebooks/train-test-60-15-25/train-test-80-20/Train-Test-80-20/Test'\n",
        "validation_dir='/content/drive/MyDrive/Colab Notebooks/train-test-60-15-25/train-test-80-20/Train-Test-80-20/Valid'\n",
        "\n",
        "labels = ['Hasta', 'Saglikli']\n",
        "img_size = 150\n",
        "\n",
        "def get_data(data_dir):\n",
        "    data = [] \n",
        "    for label in labels: \n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img))[...,::-1]\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) \n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)\n",
        "\n",
        "\n",
        "train=get_data(train_dir)\n",
        "test=get_data(test_dir)\n",
        "valid=get_data(validation_dir)\n",
        "\n",
        "\n",
        "x_train=[]\n",
        "y_train=[]\n",
        "\n",
        "x_test=[]\n",
        "y_test=[]\n",
        "\n",
        "x_val=[]\n",
        "y_val=[]\n",
        "\n",
        "\n",
        "for feature, label in train:\n",
        "    x_train.append(feature)\n",
        "    y_train.append(label)\n",
        "\n",
        "for feature, label in test:\n",
        "    x_test.append(feature)\n",
        "    y_test.append(label)\n",
        "\n",
        "for feature, label in valid:\n",
        "    x_val.append(feature)\n",
        "    y_val.append(label)\n",
        "\n",
        "\n",
        "x_train = np.array(x_train) /255.0\n",
        "x_train.reshape(-1, img_size, img_size, 1)\n",
        "y_train = np.array(y_train)\n",
        "y_train=np_utils.to_categorical(y_train) \n",
        "\n",
        "x_test = np.array(x_test) /255.0\n",
        "x_test.reshape(-1, img_size, img_size, 1)\n",
        "y_test = np.array(y_test)\n",
        "y_test=np_utils.to_categorical(y_test) \n",
        "\n",
        "x_val = np.array(x_val) /255.0\n",
        "x_val.reshape(-1, img_size, img_size, 1)\n",
        "y_val = np.array(y_val)\n",
        "y_val=np_utils.to_categorical(y_val) \n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "x_train,y_train=shuffle(x_train,y_train)\n",
        "x_test,y_test=shuffle(x_test,y_test)\n",
        "x_val,y_val=shuffle(x_val,y_val)\n",
        "\n",
        "train_datagen=ImageDataGenerator(brightness_range=(0.1,1.0))\n",
        "train_datagen.fit(x_train)\n",
        "def build_model(hp):   \n",
        "    model = keras.models.Sequential()\n",
        "\n",
        "    model.add(Conv2D(hp.Int('input_conv_units',min_value=32,max_value=512,step=32),\n",
        "                     kernel_size=3,input_shape=x_train.shape[1:]))\n",
        "    model.add(Activation('tanh'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))                \n",
        "    for i in range(hp.Int('n_of_conv_layers',1,5)):\n",
        "        model.add(Conv2D(hp.Int(f'Conv_{i}_Size',min_value=32,max_value=512,step=32),\n",
        "                  kernel_size=hp.Choice('kernel_size_of_conv'+str(i),[1,3,5,7])))\n",
        "        model.add(Activation('relu'))           \n",
        "    \n",
        "    model.add(Flatten())\n",
        "    \n",
        "    for j in range(hp.Int('n_of_dense_layers',1,5)):\n",
        "        model.add(Dense(hp.Int(f'Dense_{j}_Size',min_value=8,max_value=256,step=8)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(Dropout(hp.Float('Dropout_rate'+str(j), min_value=0.0,max_value=0.3,step=0.00000001)))\n",
        "    \n",
        "    \n",
        "    model.add(Dense(2))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "\n",
        "    model.compile(loss=\"binary_crossentropy\",\n",
        "                  optimizer=keras.optimizers.Adam(learning_rate=hp.Float('Learning_Rate',min_value=1e-5,max_value=1e-2,step=0.00000001),\n",
        "                                 beta_1=hp.Float('beta1',min_value=0.9,max_value=0.999999,step=0.00000001),\n",
        "                                 beta_2=hp.Float('beta2',min_value=0.9,max_value=0.999999,step=0.00000001)),\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner = kerastuner.tuners.bayesian.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,  \n",
        "    executions_per_trial=1,\n",
        "    directory=LOG_DIR)\n",
        "\n",
        "tuner.search_space_summary()\n",
        "\n",
        "\n",
        "tuner.search(x=x_train,\n",
        "             y=y_train,\n",
        "             epochs=30,\n",
        "             batch_size=32,\n",
        "             callbacks=[tensorboard],\n",
        "             verbose=1,\n",
        "             validation_data=(x_val, y_val))\n",
        "\n",
        "tuner.results_summary() \n",
        "\n",
        "\n",
        "with open(f\"tuner_{int(time.time())}.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tuner, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjKzWFXn9CVN"
      },
      "source": [
        "#####Transfer SEARCH BAYESIAN##############\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Activation , Dropout\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner import tuners\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "import time\n",
        "import pickle\n",
        "from keras.utils import np_utils\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import kerastuner \n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "LOG_DIR = f\"{int(time.time())}\"\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=LOG_DIR)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPooling2D, Flatten , Activation,Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import tensorflow as tf\n",
        "from hyperopt import tpe, fmin, hp\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "batch_size = 64\n",
        "img_height = 160\n",
        "img_width = 160\n",
        "\n",
        "train_dir='/content/drive/MyDrive/Colab Notebooks/Train-Test-Valid-60-20-20/Train'\n",
        "test_dir='/content/drive/MyDrive/Colab Notebooks/Train-Test-Valid-60-20-20/Test'\n",
        "validation_dir='/content/drive/MyDrive/Colab Notebooks/Train-Test-Valid-60-20-20/Valid'\n",
        "\n",
        "labels = ['Hasta', 'Saglikli']\n",
        "img_size = 160\n",
        "\n",
        "def get_data(data_dir):\n",
        "    data = [] \n",
        "    for label in labels: \n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img))[...,::-1]\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) \n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)\n",
        "\n",
        "\n",
        "\n",
        "train=get_data(train_dir)\n",
        "test=get_data(test_dir)\n",
        "valid=get_data(validation_dir)\n",
        "\n",
        "\n",
        "x_train=[]\n",
        "y_train=[]\n",
        "\n",
        "x_test=[]\n",
        "y_test=[]\n",
        "\n",
        "x_val=[]\n",
        "y_val=[]\n",
        "\n",
        "\n",
        "for feature, label in train:\n",
        "    x_train.append(feature)\n",
        "    y_train.append(label)\n",
        "\n",
        "for feature, label in test:\n",
        "    x_test.append(feature)\n",
        "    y_test.append(label)\n",
        "\n",
        "for feature, label in valid:\n",
        "    x_val.append(feature)\n",
        "    y_val.append(label)\n",
        "\n",
        "\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "y_train=np.array(y_train)\n",
        "y_val=np.array(y_val)\n",
        "\n",
        "x_test=np.array(x_test)\n",
        "x_train=np.array(x_train)\n",
        "x_val=np.array(x_val)\n",
        "\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "x_train,y_train=shuffle(x_train,y_train)\n",
        "x_test,y_test=shuffle(x_test,y_test)\n",
        "x_val,y_val=shuffle(x_val,y_val)\n",
        "\n",
        "def build_model(hp):   \n",
        "    data_augmentation = tf.keras.Sequential([\n",
        "\n",
        "    tf.keras.layers.experimental.preprocessing.RandomContrast(0.1,1.0)\n",
        "    ])\n",
        "\n",
        "    base_model = tf.keras.applications.MobileNetV2(input_shape=(img_height,img_width) + (3,),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(img_height,img_width) + (3,))\n",
        "    x = data_augmentation(inputs)\n",
        "    x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n",
        "    x = base_model(x, training=False)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    for j in range(hp.Int('n_of_dense_layers',1,5)):\n",
        "        x = tf.keras.layers.Dense(hp.Int(f'Dense_{j}_Size',min_value=8,max_value=256,step=8),activation='relu')(x)\n",
        "        x = tf.keras.layers.Dropout(hp.Float('Dropout_rate'+str(j), min_value=0.0,max_value=0.5,step=0.00000001))(x)\n",
        "    outputs = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "    model.compile(loss=\"binary_crossentropy\",\n",
        "                  optimizer=keras.optimizers.Adam(learning_rate=hp.Float('Learning_Rate',min_value=1e-5,max_value=1e-2,step=0.00000001),\n",
        "                                 beta_1=hp.Float('beta1',min_value=0.9,max_value=0.999999,step=0.00000001),\n",
        "                                 beta_2=hp.Float('beta2',min_value=0.9,max_value=0.999999,step=0.00000001)),\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner = kerastuner.tuners.bayesian.BayesianOptimization(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,  \n",
        "    executions_per_trial=1,\n",
        "    directory=LOG_DIR)\n",
        "\n",
        "tuner.search_space_summary()\n",
        "\n",
        "\n",
        "tuner.search(x=x_train,\n",
        "             y=y_train,\n",
        "             epochs=30,\n",
        "             batch_size=64,\n",
        "             callbacks=[tensorboard],\n",
        "             verbose=1,\n",
        "             validation_data=(x_val, y_val))\n",
        "\n",
        "tuner.results_summary() \n",
        "\n",
        "\n",
        "with open(f\"tuner_{int(time.time())}.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tuner, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBUE2DrPlZXN"
      },
      "source": [
        "tuner = pickle.load(open(\"tuner_1617716020.pkl\",\"rb\"))\n",
        "tuner.get_best_hyperparameters()[0].values\n",
        "tuner.get_best_models()[0].summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOUDWaKRMVdj"
      },
      "source": [
        "function ConnectButton(){\n",
        "    console.log(\"Connect pushed\"); \n",
        "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n",
        "}\n",
        "setInterval(ConnectButton,60000);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}